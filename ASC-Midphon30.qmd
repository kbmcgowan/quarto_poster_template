---
title: Listeners do not need an F1/F2 target to perceive vowel quality _or_ regional accentedness
tbl-cap-location: bottom
format:
  poster-typst: 
    size: "48x36"
    poster-authors: "Kevin B. McGowan, Stella Takvoryan"
    departments: "Department of Linguistics, University of Kentucky"
    header-color: "265CA4"
    univ-logo: "./images/Department-of-Linguistics-white.png"
    univ-image: "./images/speech-is-social.png"
    title_font_size: 80
    authors_font_size: 38

    font-size: 32
    
    footer-text: "Midphon 30"
    footer-emails: "kbmcgowan@uky.edu, stakvoryan@uky.edu"
    footer-color: "265CA4"
    footer-text-color: "FFFFFF"
    footer_text_font_color: "FFFFFF"
    footer_url_font_size: 16
    footer_text_font_size: 16
    footer-url: "Download this poster from: https://phonetics.as.uky.edu/research/asc/midphon30/"

#we want to use pandoc instead of typst for bibliography
# (so we can suppress it if we so desire)
citeproc: true
bibliography: zotero-references.bib
csl: apa.csl
suppress-bibliography: true
---

```{r}
#| label: load-data
#| message: false
#| warning: false
#| include: false
library(tidyverse)
library(ggthemes)
library(brms)
library(ggdist)
library(bayestestR)
library(marginaleffects)
library(ggpubr)
library(tidynorm)
library(geomtextpath)
library(tidybayes)
library(broom.mixed)

theme_set(theme_ggdist())
theme_set(theme_tufte())

afc_df <- read_csv("df.csv")
prod_param <- read_csv("prod_param.csv")

```

```{r}
#| label: prepare-data
#| message: false
#| warning: false
#| include: false

asc_afc <- afc_df |>
  select(
    sound_file,
    participant,
    trial_type, 
    talker,
    right,
    left,
    middle,
    vowel,
    region,
    condition, 
    response_exp_2.keys,
    response_exp.rt,
    tense_lax,
    minimal_pair,
    response_exp.keys,
    response_exp_2.rt,
    target_side
  ) |>
  filter(
    trial_type %in% c("who", "what")
  ) |>
  dplyr::rename(
    who_key = response_exp_2.keys,
    what_key = response_exp.keys,
    who_rt = response_exp_2.rt,
    what_rt = response_exp.rt,
    manipulation = condition
  ) |>
  mutate(
    response = case_when(
      target_side == "left" & who_key == "m" | target_side == "left" & what_key == "m" ~ "0",
      target_side == "left" & who_key == "z" | target_side == "left" & what_key == "z" ~ "1",
      target_side == "right" & who_key == "m" | target_side == "right" & what_key == "m" ~ "1",
      target_side == "right" & who_key == "z" | target_side == "right" & what_key == "z" ~ "0"
    )
  ) |>
  mutate(
    region = fct_relevel(
      region, "NS"
    )
  ) |>
  mutate(
    manipulation = fct_relevel(
      manipulation, "full"
    )
  ) |>
  filter(
   what_rt <= 5.0 | who_rt <= 5.0,
   talker != "SO"
  )

asc_afc$region <- asc_afc$region |>
  recode(
    "NS" = "Non-Southern",
    "S" = "Southern"
  )

asc_afc$manipulation <- asc_afc$manipulation |>
  recode(
    "sc" = "Silent center",
    "full" = "Full vowel quality"
  )

asc_afc$response <- as.numeric(asc_afc$response)

# subsetting

who_afc <- asc_afc |>
  filter(
    trial_type == "who"
  ) |>
  mutate(
    vowel = case_when(
      middle == "bought" ~ "ɔ",
      middle == "pot" ~ "a",
      middle == "beat" ~ "i",
      middle == "bit" ~ "ɪ",
      middle == "bat" ~ "æ",
      middle == "bite" ~ "aɪ",
      middle == "bet" ~ "ɛ",
      middle == "boot" ~ "u",
      middle == "but" ~ "ʌ",
      middle == "boat" ~ "o",
      middle == "put" ~ "ʊ",
      middle == "bait" ~ "e"
    )
  ) |>
  select(
    -c(what_rt, minimal_pair, what_key)
  ) |>
  filter(
    talker != "SO"
  )

who_afc$who_rt <- who_afc$who_rt |>
  as.numeric()

what_afc <- asc_afc |>
  filter(
    trial_type == "what"
  ) |>
  mutate(
    vowel = case_when(
      target_side == "left" & left == "bought" ~ "ɔ",
      target_side == "left" & left == "pot" | target_side == "right" & right == "pot" ~ "a",
      target_side == "left" & left == "beat" | target_side == "right" & right == "beat" ~ "i",
      target_side == "left" & left == "bit" | target_side == "right" & right == "bit" ~ "ɪ",
      target_side == "left" & left == "bat" | target_side == "right" & right == "bat" ~ "æ",
      target_side == "left" & left == "bite" | target_side == "right" & right == "bite" ~ "aɪ",
      target_side == "left" & left == "bet" | target_side == "right" & right == "bet" ~ "ɛ",
      target_side == "left" & left == "boot" | target_side == "right" & right == "boot" ~ "u",
      target_side == "left" & left == "but" | target_side == "right" & right == "but" ~ "ʌ",
      target_side == "left" & left == "boat" | target_side == "right" & right == "boat" ~ "o",
      target_side == "left" & left == "put" | target_side == "right" & right == "put" ~ "ʊ",
      target_side == "left" & left == "bait" | target_side == "right" & right == "bait" ~ "e",
    )
  ) |>
  select(
    -c(who_rt, who_key)
  ) |>
  mutate(
    region = fct_relevel(
      region, "Non-Southern"
    )
  ) |>
  mutate(
    manipulation = fct_relevel(
      manipulation, "Full vowel quality"
    )
  ) |>
  filter(
    talker != "SO"
  ) |>
  mutate(
    target_word = case_when(
      target_side == "left" ~ .data$left,
      target_side == "right" ~ .data$right
    )
  )

who_afc$response <- as.numeric(who_afc$response)
what_afc$response <- as.numeric(what_afc$response)

param_df <- prod_param |>
  select(
    param,
    F1:F3,
    file_name,
    id,
    label
    #prop_time
  ) |> 
  mutate(
    talker = case_when(
      str_detect(
        file_name, "AC"
        ) ~ "AC",
      str_detect(
        file_name, "KL"
        ) ~ "KL",
      str_detect(
        file_name, "SO"
      ) ~ "SO", 
      str_detect(
        file_name, "W3"
        ) ~ "W3",
      str_detect(
        file_name, "W6"
        ) ~ "W6",
      str_detect(
        file_name, "W9"
      ) ~ "W9"
    )
  ) |>
    filter(
      talker != "SO"
    ) |>
  mutate( # change from new-FAVE transcription to IPA 
   label = case_when(
     str_detect(
       file_name, "bait"
     ) ~ "eɪ",
     str_detect(
       file_name, "bet"
     ) ~ "ɛ",
     str_detect(
       file_name, "beat"
     ) ~ "i",
     str_detect(
       file_name, "bit"
     ) ~ "ɪ",
     str_detect(
       file_name, "bat"
     ) ~ "æ",
     str_detect(
       file_name, "bought"
     ) ~ "ɔ",
     str_detect(
       file_name, "boat"
     ) ~ "o",
     str_detect(
       file_name, "but"
     ) ~ "ʌ",
     str_detect(
       file_name, "boot"
     ) ~ "u",
     str_detect(
       file_name, "put"
     ) ~ "ʊ",
     str_detect(
       file_name, "pot"
     ) ~ "a",
    str_detect(
       file_name, "bite"
     ) ~ "aɪ"
   )
 ) |>
  mutate(
    region = case_when(
      talker == "AC" | talker == "KL" ~ "southern",
      .default = "nonsouthern"
    )
  )
```

# Background

Silent centers (SC): listeners can identify vowel quality in a CVC syllable even with 65% of tense vowels and 50% of lax vowels removed [@strange2013]. However, listeners may still require vowel centers to hear social information. Three complementary ideas in the literature suggest that social information in vowel centers may be *essential*:

\
1. **Primacy of F1/F2 at the vowel midpoint**, sometimes taken along with duration, e.g., sociophonetics, sound change, second language acquisition, etc. [@labov1972; @nycz2013best; @10.1121/10.0000494; @thomas2014]

1.  **Hybrid silent centers** [@rakerd1987evidence; @verbrugge1986evidence]: pairing SC syllable edges from different talkers does not undermine vowel perception so argue vowel edges do not carry social information

2.  **Vowel normalization** [@johnson2005; @johnson2021speaker] assumes that variation is problematic for listeners so models typically operate on vowel centers where contextual variation is least \[c.f. [@barreda2025; @fruehwald2024working]\]

# Methodology

-   **Talkers**: Three non-Southern talkers from the Wildcat corpus [@Wildcat2010] and two Southern talkers (KY)

-   **Stimuli**: BVT syllables with \[i, ɪ, e, ɛ, æ, u, ʊ, o, ʌ, ɔ, a\]; **middle 50% for lax vowels** & **middle 65% for tense vowels** [@10.1121/1.389855] excised with a custom Praat script (see @fig-worms)

-   **Procedure**: 2AFC; listeners heard a CVC word and answered either "what did you hear?" with a pair of words or "who did you hear?" and the maps in @fig-maps. "What?" trials displayed a map congruent with the talker; "Who?" task trials displayed the word that was being spoken.

\

!["Non-Southern" and "Southern" stimuli](./images/maps.png){#fig-maps width="80%"}

\

-   **Participants**: 60 US participants recruited via Prolific

-   **Analysis**: BRMS logistic regression in R [@bürkner2017], NHST with bayestestR [@makowski2019; @arel-bundock2024]

-   Many studies have found that listeners perform poorly when asked to label regional accents [@milroy1977; @clopper2004; @campbell2025place]. Our simplified maps are intended to represent Clopper & Pisoni's "dialect clusters"

-   While it is clear that listeners do not need vowel centers to perceive vowel quality accurately, it is not yet known whether listeners can perceive, for example, regional accent without the vowel center.

\
\

::::: {layout-ncol="2"}
<div>

# Predictions

![Predictions under two assumptions about social information](./images/ASC-SDT.png){#fig-predictions width="95%"}

</div>

<div>

# Silent Centers Visualized

```{r}
#| label: fig-worms
#| echo: FALSE
#| out.width: 100%
#| fig.cap: "Vowel stimuli unnormed F1/F2 DCTS with excised portions indicated"
#| fig.align: "center"

param_idct_unnorm <- param_df |>
  mutate( 
    label = fct_relevel(
      label,
      c("i", "ɪ", "eɪ", "ɛ", "æ", "u", "ʊ", "o", "ʌ", "a", "ɔ")
    )
  ) |>
  summarise(
    .by = c(label, param, region),
    across(
      F1:F2,
      mean
    )
  ) |>
  reframe_with_idct( 
    F1:F2, 
    .by = c(label, region), 
    .token_id_col = label, 
    .param_col = param,
    .n = 100
    )
  
traj_idct_unnorm <- param_idct_unnorm |>   
  mutate(
    selection = case_when(
      label == "æ" | label == "ɛ" | label == "ɪ" | label == "ʌ" | label == "a" | label == "ʊ" & .time < 25 & .time > 75 ~ "edges",
      label == "æ" | label == "ɛ" | label == "ɪ" | label == "ʌ" | label == "a" | label == "ʊ" & .time > 25 & .time < 75 ~ "center",
      label == "eɪ" | label == "i" | label == "o" | label == "u" | label == "ɔ" & .time < 18 & .time > 73 ~ "edges",
      label == "eɪ" | label == "i" | label == "o" | label == "u" | label == "ɔ" & .time > 18 & .time < 73 ~ "center",
    )
  ) |>
  mutate(
    label = fct_relevel(
      label,
      c("i", "ɪ", "eɪ", "ɛ", "æ", "u", "ʊ", "o", "ʌ", "a", "ɔ")
    )
  ) |>
  mutate(
    type = case_when(
      label == "æ" | label == "ɛ" | label == "ɪ" | label == "ʌ" | label == "a" | label == "ʊ" ~ "lax",
      .default = "tense"
    )
  ) |>
  mutate(
    portion = case_when(
      type == "tense" & between(.time, 18, 83) ~ "center",
      type == "tense" & .time <= 18 | .time >= 83 ~ "edges",
      type == "lax" & between(.time, 25, 75) ~ "center",
      type == "lax" & .time <= 25 | .time >= 75 ~ "edges"
    )
  ) |>
  pivot_longer(
    cols = c(F1:F2),
    names_to = "formant",
    values_to = "hz"
  )

traj_idct_unnorm$region <- traj_idct_unnorm$region |>
  recode(
    "southern" = "Southern",
    "nonsouthern" = "Non-Southern"
  )
  
traj_idct_unnorm |>
  ggplot(
    aes(
      y = hz,
      x = .time, 
      group = formant,
      color = portion
    )
  ) +
  geom_path() + 
  facet_grid(region~label) +
  scale_x_continuous(
    breaks = c(1, 100)
  ) + 
  scale_color_manual(
    values = c("thistle3", "black")
  ) +
  labs(
    x = "Time (proportional)",
    y = "Frequency",
    color = "Vowel"
  ) +
   theme(
    text = element_text(family = "Helvetica Neue"),
    axis.text = element_text(size = 6)
  )

```

</div>
:::::

# Results

```{r}
#| label: modeling
#| message: false
#| warning: false
#| include: false

what_mod1 <- brm(
  response ~ manipulation * region * tense_lax + (1 | participant) + (1 | target_word),
  data = what_afc,
  backend = "cmdstanr",
  family = bernoulli(),
  file = "models/what_mod1",
  file_refit = "on_change",
  warmup = 1000, iter = 5000, chains = 4,
  cores = 6
)

who_mod1 <- brm(
  response ~ manipulation * region * tense_lax + (1 | participant) + (1 | middle),
  data = who_afc,
  backend = "cmdstanr",
  family = bernoulli(),
  file = "models/who_mod1",
  file_refit = "on_change",
  warmup = 1000, iter = 5000, chains = 4,
  cores = 6
)

what_rt_mod <- brm(
  what_rt ~ manipulation * region * tense_lax + (1 | participant) + (1 | minimal_pair),
  data = what_afc,
  backend = "cmdstanr",
  family = lognormal(),
  file = "models/what_rt_mod",
  file_refit = "on_change",
  warmup = 1000, iter = 5000, chains = 4,
  cores = 6
)

who_rt_mod <- brm(
  who_rt ~ manipulation * region * tense_lax + (1 | participant) + (1 | middle),
  data = who_afc,
  backend = "cmdstanr",
  family = lognormal(),
  file = "models/who_rt_mod",
  file_refit = "on_change",
  warmup = 1000, iter = 5000, chains = 4,
  cores = 6
)
```

```{r}
#| label: fig-model-predictions
#| echo: false
#| message: false
#| warning: false
#| out.width: 100%
#| fig.cap: "'What?' (top left) and 'Who?' (bottom left) model predictions (95% HDI) and Accuracy differences for responses to Non-Southern (top row) and Southern (bottom row) talkers"
#| fig.align: "center"

what_pred <- what_mod1 |>
  plot_predictions(
    newdata = datagrid(
      manipulation = unique,
      region = unique,
      tense_lax = unique
    ),
    by = c("manipulation", "region", "tense_lax"),
    re_formula = NA,
    type = "link",
    draw = FALSE
  ) |>
  ggplot(
    aes(
      x = region,
      y = estimate,
      fill = manipulation
    )
  ) +
  geom_bar(
    stat = "identity",
    position = "dodge"
    ) +
  geom_pointrange(
    aes(
      ymin = conf.low,
      ymax = conf.high
    ),
    position=position_dodge(width = 0.9),
    size = .3
  )  +
  labs(
    y = "Likelihood of target (What?)",
    x = "",
    fill = "",
   # title = "'What?'",
    caption = "response ~ manipulation * region * tense_lax + (1|participant) + (1|target_word)"
  ) +
  scale_fill_manual(
    values = c("thistle3", "mediumpurple4")
  ) +
  facet_grid(~tense_lax) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.caption = element_text(size = 5),
    axis.title.y = element_text(size = 7),
    axis.title.x = element_text(size = 7)
  )

who_pred <- who_mod1 |>
  plot_predictions(
    newdata = datagrid(
      manipulation = unique,
      region = unique,
      tense_lax = unique
    ),
    by = c("manipulation", "region", "tense_lax"),
    re_formula = NA,
    type = "link",
    draw = FALSE
  ) |>
  ggplot(
    aes(
      x = region,
      y = estimate,
      fill = manipulation
    )
  ) +
  geom_bar(
    stat = "identity",
    position = "dodge"
    ) +
  geom_pointrange(
    aes(
      ymin = conf.low,
      ymax = conf.high
    ),
    position=position_dodge(width = 0.9),
    size = .3
  )  +
  labs(
    y = "Likelihood of target (Who?)",
    x = "",
    fill = "",
   # title = "'Who?'",
    caption = "response ~ manipulation * region * tense_lax + (1|participant) + (1|middle)"
  )  +
  scale_fill_manual(
    values = c("thistle3", "mediumpurple4")
  ) +
  facet_grid(~tense_lax) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.caption = element_text(size = 5),
    axis.title.y = element_text(size = 7),
    axis.title.x = element_text(size = 7)
  )

predictions <- ggarrange(
  what_pred,
  who_pred,
  nrow = 2,
  common.legend = TRUE
)

who <- who_afc |>
  mutate(
    sound_file = str_replace(
      sound_file,
      pattern = "resources/", replacement = ""
    )
  ) |>
  mutate(
    sound_file = str_replace(
      sound_file,
      pattern = "-SC.wav", replacement = ""
  )
  ) |>
  mutate(
    sound_file = str_replace(
      sound_file,
      pattern = ".wav", replacement = ""
  )
  )

what <- what_afc |>
  mutate(
    sound_file = str_replace(
      sound_file,
      pattern = "resources/", replacement = ""
    )
  ) |>
  mutate(
    sound_file = str_replace(
      sound_file,
      pattern = "-SC.wav", replacement = ""
  )
  ) |>
  mutate(
    sound_file = str_replace(
      sound_file,
      pattern = ".wav", replacement = ""
  )
  )

# merge

who_dct <- merge(
  who, 
  param_df,
  by.x = "sound_file",
  by.y = "file_name"
)

what_dct <- merge(
  what, 
  param_df,
  by.x = "sound_file",
  by.y = "file_name"
)

who_dct <- who_dct |>
   pivot_longer(
    cols = F1:F2,
    names_to = "formants",
    values_to = "hz"
  ) |>
  filter(
    param <= 2
  ) |>
  pivot_wider(
    names_from = c(formants, param),
    values_from = "hz"
  )

south_who_dct <- who_dct |>
  filter(
    region.y == "southern"
  )

nonsouth_who_dct <- who_dct |>
  filter(
    region.y == "nonsouthern"
  )

what_dct <- what_dct |>
   pivot_longer(
    cols = F1:F2,
    names_to = "formants",
    values_to = "hz"
  ) |>
  filter(
    param <= 2
  ) |>
  pivot_wider(
    names_from = c(formants, param),
    values_from = "hz"
  )

south_what_dct <- what_dct |>
  filter(
    region.y == "southern"
  )

nonsouth_what_dct <- what_dct |>
  filter(
    region.y == "nonsouthern"
  )

# models

south_who_dct_mod <- brm(
  response ~ (F1_1 + F2_1) * manipulation * tense_lax + (1 | participant) + (1 | vowel),
  data = south_who_dct,
  backend = "cmdstanr",
  family = bernoulli(),
  file = "models/south_who_dct",
  file_refit = "on_change",
  warmup = 1000, iter = 5000, chains = 4,
  cores = 6
)

nonsouth_who_dct_mod <- brm(
  response ~ (F1_1 + F2_1) * manipulation * tense_lax + (1 | participant) + (1 | vowel),
  data = nonsouth_who_dct,
  backend = "cmdstanr",
  family = bernoulli(),
  file = "models/nonsouth_who_dct",
  file_refit = "on_change",
  warmup = 1000, iter = 5000, chains = 4,
  cores = 6
)

nonsouth_what_dct_mod <- brm(
  response ~ (F1_1 + F2_1) * manipulation * tense_lax + (1 | participant) + (1 | vowel),
  data = nonsouth_what_dct,
  backend = "cmdstanr",
  family = bernoulli(),
  file = "models/nonsouth_what_dct",
  file_refit = "on_change",
  warmup = 1000, iter = 5000, chains = 4,
  cores = 6
)

south_what_dct_mod <- brm(
  response ~ (F1_1 + F2_1) * manipulation * tense_lax + (1 | participant) + (1 | vowel),
  data = south_what_dct,
  backend = "cmdstanr",
  family = bernoulli(),
  file = "models/south_what_dct",
  file_refit = "on_change",
  warmup = 1000, iter = 5000, chains = 4,
  cores = 6
)

# avg comparisons
south_who <- plot_comparisons(
  south_who_dct_mod,
  variables = "manipulation",
  by = "tense_lax"
) +
  labs(
    x = "",
    y = " ",
    title = "'Who?'",
    caption = " "
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 9),
    axis.title.y = element_text(size = 8)
  )

nonsouth_who <- plot_comparisons(
  nonsouth_who_dct_mod,
  variables = "manipulation",
  by = "tense_lax"
) +
  labs(
    x = "",
    y = " ",
    title = "'Who?'"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 9),
    axis.title.y = element_text(size = 8)
  )

south_what <- plot_comparisons(
  south_what_dct_mod,
  variables = "manipulation",
  by = "tense_lax"
) +
  labs(
    x = "",
    y = "Accuracy Δ (Southern)",
    title = "'What?'"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 9),
    axis.title.y = element_text(size = 8)
  )

nonsouth_what <- plot_comparisons(
  nonsouth_what_dct_mod,
  variables = "manipulation",
  by = "tense_lax"
) +
  labs(
    x = "",
    y = "Accuracy Δ (Non-Southern)",
    title = "'What?'"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 9),
    axis.title.y = element_text(size = 8)
  )

comparisons <- ggarrange(
  nonsouth_what,
  nonsouth_who,
  south_what,
  south_who
)

ggarrange(
  predictions,
  comparisons
)
```

# Discussion

-   **Listeners do not need the vowel center to perceive vowel quality (replicated)**: Listener accuracy on the 'what?' trials is a straightforward, successful replication of the silent centers effect [@strange2013; @10.1121/1.389855]
-   **Listeners do not need the vowel center to perceive regional accentedness**: Contra hybrid silent-centers work that paired incongruous syllable edges[@verbrugge1986evidence; @rakerd1987evidence], listeners to the 'who?' trials can, indeed, perceive regional accent from SC vowels
-   **Regional differences for tense and lax vowel qualities**: different vowel qualities encode regional variation differently; some of this variation is captured by the tense/lax distinction

# Conclusions & Future Work

-   With V centers removed, social perception is possible, but not quite as robust as vowel quality. Centers may be more useful to listeners as a source of social information, but they are not essential.

-   Researchers who use a single point measure to characterize the vowels of a talker or of a community are missing a great deal of information that listeners themselves use in perception.

-   But even formant tracks or multiple points of measurement per vowel are only measuring vowel centers if they begin at 20% (or later) and end at 80% of V duration as the standard SC manipulation removes from 17.5% of a tense vowel to 82.5%

-   Tense/Lax: it may be that listeners need a greater percentage of a more dynamic vowel quality to perceive regional variation or this may be due to varying levels of awareness/stereotypicallity of vowels [@Babel2025]\
\

![Schematic from original Silent Centers work](./images/StrangeJenkins2013.png){#fig-strange width="50%"}
\

::::: {layout-ncol="2"}
<div>

# References

```{r, echo=FALSE}
#| message: false
#| warning: false
library(qrcode)
refs <- qr_code("https://phonetics.as.uky.edu/research/asc/midphon30/#references")
plot(refs)
```

</div>

<div>

# Thanks

We are grateful to Josef Fruehwald, Jennifer Cramer, Kyler Laycock, Kendal Smith, Austin Coleman, and Shane O'Nan for their invaluable assistance with this project.

</div>
:::::
