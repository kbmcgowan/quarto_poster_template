---
title: Listeners do not need an F1/F2 target to perceive vowel quality _or_ regional accentedness
tbl-cap-location: bottom
format:
  poster-typst: 
    size: "48x36"
    poster-authors: "Kevin B. McGowan, Stella Takvoryan"
    departments: "Department of Linguistics, University of Kentucky"
    header-color: "265CA4"
    univ-logo: "./images/Department-of-Linguistics-white.png"
    univ-image: "./images/speech-is-social.png"
    title_font_size: 80
    authors_font_size: 38

    font-size: 32
    
    footer-text: "Midphon 30"
    footer-emails: "kbmcgowan@uky.edu, stakvoryan@uky.edu"
    footer-color: "265CA4"
    footer-text-color: "FFFFFF"
    footer_text_font_color: "FFFFFF"
    footer_url_font_size: 16
    footer_text_font_size: 16
    footer-url: "Download this poster from: https://phonetics.as.uky.edu/research/asc/midphon30/"

#we want to use pandoc instead of typst for bibliography
# (so we can suppress it if we so desire)
citeproc: true
bibliography: zotero-references.bib
csl: apa.csl
suppress-bibliography: true
---

```{r}
#| label: load-data
#| message: false
#| warning: false
#| include: false
library(tidyverse)
library(ggthemes)
library(brms)
library(ggdist)
library(bayestestR)
library(marginaleffects)
library(ggpubr)
library(tidynorm)
library(geomtextpath)
library(tidybayes)
library(broom.mixed)

theme_set(theme_ggdist())
theme_set(theme_tufte())

afc_df <- read_csv("df.csv")
prod_param <- read_csv("prod_param.csv")

```

```{r}
#| label: prepare-data
#| message: false
#| warning: false
#| include: false

asc_afc <- afc_df |>
  select(
    sound_file,
    participant,
    trial_type, 
    talker,
    right,
    left,
    middle,
    vowel,
    region,
    condition, 
    response_exp_2.keys,
    response_exp.rt,
    tense_lax,
    minimal_pair,
    response_exp.keys,
    response_exp_2.rt,
    target_side
  ) |>
  filter(
    trial_type %in% c("who", "what")
  ) |>
  dplyr::rename(
    who_key = response_exp_2.keys,
    what_key = response_exp.keys,
    who_rt = response_exp_2.rt,
    what_rt = response_exp.rt,
    manipulation = condition
  ) |>
  mutate(
    response = case_when(
      target_side == "left" & who_key == "m" | target_side == "left" & what_key == "m" ~ "0",
      target_side == "left" & who_key == "z" | target_side == "left" & what_key == "z" ~ "1",
      target_side == "right" & who_key == "m" | target_side == "right" & what_key == "m" ~ "1",
      target_side == "right" & who_key == "z" | target_side == "right" & what_key == "z" ~ "0"
    )
  ) |>
  mutate(
    region = fct_relevel(
      region, "NS"
    )
  ) |>
  mutate(
    manipulation = fct_relevel(
      manipulation, "full"
    )
  ) |>
  filter(
   what_rt <= 5.0 | who_rt <= 5.0,
   talker != "SO"
  )

asc_afc$region <- asc_afc$region |>
  recode(
    "NS" = "Non-Southern",
    "S" = "Southern"
  )

asc_afc$manipulation <- asc_afc$manipulation |>
  recode(
    "sc" = "Silent center",
    "full" = "Full vowel quality"
  )

asc_afc$response <- as.numeric(asc_afc$response)

# subsetting

who_afc <- asc_afc |>
  filter(
    trial_type == "who"
  ) |>
  mutate(
    vowel = case_when(
      middle == "bought" ~ "ɔ",
      middle == "pot" ~ "a",
      middle == "beat" ~ "i",
      middle == "bit" ~ "ɪ",
      middle == "bat" ~ "æ",
      middle == "bite" ~ "aɪ",
      middle == "bet" ~ "ɛ",
      middle == "boot" ~ "u",
      middle == "but" ~ "ʌ",
      middle == "boat" ~ "o",
      middle == "put" ~ "ʊ",
      middle == "bait" ~ "e"
    )
  ) |>
  select(
    -c(what_rt, minimal_pair, what_key)
  ) |>
  filter(
    talker != "SO"
  )

who_afc$who_rt <- who_afc$who_rt |>
  as.numeric()

what_afc <- asc_afc |>
  filter(
    trial_type == "what"
  ) |>
  mutate(
    vowel = case_when(
      target_side == "left" & left == "bought" ~ "ɔ",
      target_side == "left" & left == "pot" | target_side == "right" & right == "pot" ~ "a",
      target_side == "left" & left == "beat" | target_side == "right" & right == "beat" ~ "i",
      target_side == "left" & left == "bit" | target_side == "right" & right == "bit" ~ "ɪ",
      target_side == "left" & left == "bat" | target_side == "right" & right == "bat" ~ "æ",
      target_side == "left" & left == "bite" | target_side == "right" & right == "bite" ~ "aɪ",
      target_side == "left" & left == "bet" | target_side == "right" & right == "bet" ~ "ɛ",
      target_side == "left" & left == "boot" | target_side == "right" & right == "boot" ~ "u",
      target_side == "left" & left == "but" | target_side == "right" & right == "but" ~ "ʌ",
      target_side == "left" & left == "boat" | target_side == "right" & right == "boat" ~ "o",
      target_side == "left" & left == "put" | target_side == "right" & right == "put" ~ "ʊ",
      target_side == "left" & left == "bait" | target_side == "right" & right == "bait" ~ "e",
    )
  ) |>
  select(
    -c(who_rt, who_key)
  ) |>
  mutate(
    region = fct_relevel(
      region, "Non-Southern"
    )
  ) |>
  mutate(
    manipulation = fct_relevel(
      manipulation, "Full vowel quality"
    )
  ) |>
  filter(
    talker != "SO"
  ) |>
  mutate(
    target_word = case_when(
      target_side == "left" ~ .data$left,
      target_side == "right" ~ .data$right
    )
  )

who_afc$response <- as.numeric(who_afc$response)
what_afc$response <- as.numeric(what_afc$response)

param_df <- prod_param |>
  select(
    param,
    F1:F3,
    file_name,
    id,
    label
    #prop_time
  ) |> 
  mutate(
    talker = case_when(
      str_detect(
        file_name, "AC"
        ) ~ "AC",
      str_detect(
        file_name, "KL"
        ) ~ "KL",
      str_detect(
        file_name, "SO"
      ) ~ "SO", 
      str_detect(
        file_name, "W3"
        ) ~ "W3",
      str_detect(
        file_name, "W6"
        ) ~ "W6",
      str_detect(
        file_name, "W9"
      ) ~ "W9"
    )
  ) |>
    filter(
      talker != "SO"
    ) |>
  mutate( # change from new-FAVE transcription to IPA 
   label = case_when(
     str_detect(
       file_name, "bait"
     ) ~ "eɪ",
     str_detect(
       file_name, "bet"
     ) ~ "ɛ",
     str_detect(
       file_name, "beat"
     ) ~ "i",
     str_detect(
       file_name, "bit"
     ) ~ "ɪ",
     str_detect(
       file_name, "bat"
     ) ~ "æ",
     str_detect(
       file_name, "bought"
     ) ~ "ɔ",
     str_detect(
       file_name, "boat"
     ) ~ "o",
     str_detect(
       file_name, "but"
     ) ~ "ʌ",
     str_detect(
       file_name, "boot"
     ) ~ "u",
     str_detect(
       file_name, "put"
     ) ~ "ʊ",
     str_detect(
       file_name, "pot"
     ) ~ "a",
    str_detect(
       file_name, "bite"
     ) ~ "aɪ"
   )
 ) |>
  mutate(
    region = case_when(
      talker == "AC" | talker == "KL" ~ "southern",
      .default = "nonsouthern"
    )
  )
```

# Background

Silent centers (SC): listeners can identify vowel quality in a CVC syllable even with 65% of tense vowels and 50% of lax vowels removed [@strange2013]. However, listeners may still require vowel centers to hear social information. Three complementary ideas in the literature suggest that social information in vowel centers may be *essential*:

\
1. **Primacy of F1/F2 at the vowel midpoint**, sometimes taken along with duration, e.g., sociophonetics, sound change, second language acquisition, etc. [@labov1972; @nycz2013best; @10.1121/10.0000494; @thomas2014]

1.  **Hybrid silent centers** [@rakerd1987evidence; @verbrugge1986evidence]: pairing SC syllable edges from different talkers does not undermine vowel perception so argue vowel edges do not carry social information

2.  **Vowel normalization** [@johnson2005; @johnson2021speaker] assumes that variation is problematic for listeners so models typically operate on vowel centers where contextual variation is least [@barreda2025reintroducing] XXX cite Joe here too

# Methodology

-   **Talkers**: Three non-Southern talkers from the Wildcat corpus [@Wildcat2010] and two Southern talkers recorded in Kentucky

-   **Stimuli**: BVT syllables with \[i, ɪ, e, ɛ, æ, u, ʊ, o, ʌ, ɔ, a\]; **middle 50% for lax vowels** & **middle 65% for tense vowels** [@10.1121/1.389855] excised with a custom Praat script (see @fig-worms)

-   **Procedure**: 2AFC; listeners heard a CVC word and answered either "what did you hear?" with a pair of words or "who did you hear?" and the maps in @fig-maps. "What?" trials displayed a map congruent with the talker; "Who?" task trials displayed the word that was being spoken.

\

!["Non-Southern" and "Southern" stimuli](./images/maps.png){#fig-maps width="80%"}

\

-   **Participants**: 60 US participants recruited via Prolific

-   **Analysis**: BRMS logistic regression in R [@bürkner2017], NHST with bayestestR [@makowski2019]

-   Many studies have found that listeners perform poorly when asked to label regional accents [@milroy1977; @clopper2004; @campbell2025place]. Our simplified maps are intended to represent Clopper & Pisoni's "dialect clusters"

-   While it is clear that listeners do not need vowel centers to perceive vowel quality accurately, it is not yet known whether listeners can perceive, for example, regional accent without the vowel center.

\
\

::::: {layout-ncol="2"}
<div>

# Predictions

![Predictions under two assumptions about social information](./images/ASC-SDT.png){#fig-predictions width="95%"}

</div>

<div>

# Silent Centers Visualized

```{r}
#| label: fig-worms
#| echo: FALSE
#| out.width: 100%
#| fig.cap: "Vowel stimuli DCTS with excised portions indicated"
#| fig.align: "center"

param_idct_unnorm <- param_df |>
  mutate( 
    label = fct_relevel(
      label,
      c("i", "ɪ", "eɪ", "ɛ", "æ", "u", "ʊ", "o", "ʌ", "a", "ɔ")
    )
  ) |>
  summarise(
    .by = c(label, param, region),
    across(
      F1:F2,
      mean
    )
  ) |>
  reframe_with_idct( 
    F1:F2, 
    .by = c(label, region), 
    .token_id_col = label, 
    .param_col = param,
    .n = 100
    )
  
traj_idct_unnorm <- param_idct_unnorm |>   
  mutate(
    selection = case_when(
      label == "æ" | label == "ɛ" | label == "ɪ" | label == "ʌ" | label == "a" | label == "ʊ" & .time < 25 & .time > 75 ~ "edges",
      label == "æ" | label == "ɛ" | label == "ɪ" | label == "ʌ" | label == "a" | label == "ʊ" & .time > 25 & .time < 75 ~ "center",
      label == "eɪ" | label == "i" | label == "o" | label == "u" | label == "ɔ" & .time < 18 & .time > 73 ~ "edges",
      label == "eɪ" | label == "i" | label == "o" | label == "u" | label == "ɔ" & .time > 18 & .time < 73 ~ "center",
    )
  ) |>
  mutate(
    label = fct_relevel(
      label,
      c("i", "ɪ", "eɪ", "ɛ", "æ", "u", "ʊ", "o", "ʌ", "a", "ɔ")
    )
  ) |>
  mutate(
    type = case_when(
      label == "æ" | label == "ɛ" | label == "ɪ" | label == "ʌ" | label == "a" | label == "ʊ" ~ "lax",
      .default = "tense"
    )
  ) |>
  mutate(
    portion = case_when(
      type == "tense" & between(.time, 18, 83) ~ "center",
      type == "tense" & .time <= 18 | .time >= 83 ~ "edges",
      type == "lax" & between(.time, 25, 75) ~ "center",
      type == "lax" & .time <= 25 | .time >= 75 ~ "edges"
    )
  ) |>
  pivot_longer(
    cols = c(F1:F2),
    names_to = "formant",
    values_to = "hz"
  )

traj_idct_unnorm$region <- traj_idct_unnorm$region |>
  recode(
    "southern" = "Southern",
    "nonsouthern" = "Non-Southern"
  )
  
traj_idct_unnorm |>
  ggplot(
    aes(
      y = hz,
      x = .time, 
      group = formant,
      color = portion
    )
  ) +
  geom_path() + 
  facet_grid(region~label) +
  scale_x_continuous(
    breaks = c(1, 100)
  ) + 
  scale_color_manual(
    values = c("thistle3", "black")
  ) +
  labs(
    x = "Time (proportional)",
    y = "Frequency",
    color = "Vowel"
  ) +
   theme(
    text = element_text(family = "Helvetica Neue"),
    axis.text = element_text(size = 6)
  )

```

</div>
:::::

# Results

We will place a figure or image below using markdown syntax. We can specify the caption and specifying height or width (or both). The figures are numbered automatically.

```{r}
#| echo: FALSE
#| out.width: 100%
#| fig.cap: "The details of a specific serif font."
#| fig.align: "center"
knitr::include_graphics('./images/Standard_lettering.png')
```

\
\
\

# Discussion

{{< lipsum 3 >}}

\
\

::::: {layout-ncol="2"}
<div>

# References

```{r, echo=FALSE}
#| message: false
#| warning: false
library(qrcode)
refs <- qr_code("https://phonetics.as.uky.edu/research/asc/midphon30/#references")
plot(refs)
```

</div>

<div>

# Thanks

We are grateful to Josef Fruehwald, Jennifer Cramer, Kyler Laycock, Kendal Smith, XXXSella's Partner, and Shane O'Nan for their invaluable assistance with this project.

</div>
:::::
